{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition: Disease Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial from https://appliedmachinelearning.blog/2019/04/01/training-deep-learning-based-named-entity-recognition-from-scratch-disease-extraction-hackathon/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import unicodedata\n",
    " \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense\n",
    "from keras.layers import TimeDistributed, Dropout, Bidirectional\n",
    " \n",
    "# Defining Constants\n",
    " \n",
    "# Maximum length of text sentences\n",
    "MAXLEN = 180\n",
    "# Number of LSTM units\n",
    "LSTM_N = 150\n",
    "# batch size\n",
    "BS=48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if GPU is enabled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7785096482919198375\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 10729594913264868872\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5065308776090252323\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7427958375\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1973663827580528049\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/tf/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the training set\n",
    "data = pd.read_csv(\"/usr/tf/notebooks/dataset/train.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle-Income</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Countries</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Burden</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Drivers</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Doc_ID  Sent_ID           Word tag\n",
       "0   1       1        1        Obesity   O\n",
       "1   2       1        1             in   O\n",
       "2   3       1        1           Low-   O\n",
       "3   4       1        1            and   O\n",
       "4   5       1        1  Middle-Income   O\n",
       "5   6       1        1      Countries   O\n",
       "6   7       1        1              :   O\n",
       "7   8       1        1         Burden   O\n",
       "8   9       1        1              ,   O\n",
       "9  10       1        1        Drivers   O"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of uniques docs, sentences and words in Training set:\n",
      " id         4543833\n",
      "Doc_ID       30000\n",
      "Sent_ID     191282\n",
      "Word        184505\n",
      "tag              3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of uniques docs, sentences and words in Training set:\\n\",data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4543834</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>CCCVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4543835</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4543836</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>MANOVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4543837</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4543838</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4543839</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4543840</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>hen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4543841</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4543842</td>\n",
       "      <td>30001</td>\n",
       "      <td>191284</td>\n",
       "      <td>Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4543843</td>\n",
       "      <td>30001</td>\n",
       "      <td>191284</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Doc_ID  Sent_ID      Word\n",
       "0  4543834   30001   191283     CCCVA\n",
       "1  4543835   30001   191283         ,\n",
       "2  4543836   30001   191283    MANOVA\n",
       "3  4543837   30001   191283         ,\n",
       "4  4543838   30001   191283        my\n",
       "5  4543839   30001   191283     black\n",
       "6  4543840   30001   191283       hen\n",
       "7  4543841   30001   191283         .\n",
       "8  4543842   30001   191284  Comments\n",
       "9  4543843   30001   191284        on"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the test set\n",
    "test_data = pd.read_csv(\"/usr/tf/notebooks/dataset/test.csv\", encoding=\"latin1\")\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of uniques docs, sentences and words in Training set:\n",
      " id         4543833\n",
      "Doc_ID       30000\n",
      "Sent_ID     191282\n",
      "Word        184505\n",
      "tag              3\n",
      "dtype: int64\n",
      "\n",
      "Number of uniques docs, sentences and words in Test set:\n",
      " id         2994463\n",
      "Doc_ID       20000\n",
      "Sent_ID     125840\n",
      "Word        139891\n",
      "dtype: int64\n",
      "\n",
      "Length of vocabulary =  257203\n",
      "\n",
      "number of tags =  3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of uniques docs, sentences and words in Training set:\\n\",data.nunique())\n",
    "print(\"\\nNumber of uniques docs, sentences and words in Test set:\\n\",test_data.nunique())\n",
    " \n",
    "# Creating a vocabulary\n",
    "words = list(set(data[\"Word\"].append(test_data[\"Word\"]).values))\n",
    "words.append(\"ENDPAD\")\n",
    " \n",
    "# Converting greek characters to ASCII characters eg. 'naïve café' to 'naive cafe'\n",
    "words = [unicodedata.normalize('NFKD', str(w)).encode('ascii','ignore') for w in words]\n",
    "n_words = len(words)\n",
    "print(\"\\nLength of vocabulary = \",n_words)\n",
    " \n",
    "tags = list(set(data[\"tag\"].values))\n",
    "n_tags = len(tags)\n",
    "print(\"\\nnumber of tags = \",n_tags)\n",
    " \n",
    "# Creating words to indices dictionary.\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "# Creating tags to indices dictionary.\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-indications', 'I-indications', 'O']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target ‘tag’ follows the Inside-outside-beginning (IOB) tagging format. The IOB format (short for inside, outside, beginning) is a common tagging format for tagging tokens in named entity recognition. The target ‘tag’ has three kinds of tags:\n",
    "\n",
    "1. B-indications : Beginning tag indicates that the token is the beginning of a disease entity (disease name in this case).\n",
    "2. I-indications : Inside tag indicates that the token is inside an entity.\n",
    "3. O : Outside tag indicates that a token is outside a disease entity.\n",
    "\n",
    "Therefore, any word which does not represent the disease name has to be classified as “O” tag. Similarly, the first word of disease name has to be classified as “B-Indication” and following words of disease name as “I-Indication”.\n",
    "\n",
    "An example with IOB format:\n",
    "\n",
    "```\n",
    "Alex I-PER\n",
    "is O\n",
    "going O\n",
    "to O\n",
    "Los B-LOC\n",
    "Angeles I-LOC\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>strategies</td>\n",
       "      <td>B-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>MICROCEPHALIA</td>\n",
       "      <td>B-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>VERA</td>\n",
       "      <td>I-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>234</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>reactive</td>\n",
       "      <td>B-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>hyperemia</td>\n",
       "      <td>I-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543377</th>\n",
       "      <td>4543378</td>\n",
       "      <td>29999</td>\n",
       "      <td>191264</td>\n",
       "      <td>hepatitis</td>\n",
       "      <td>I-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543398</th>\n",
       "      <td>4543399</td>\n",
       "      <td>29999</td>\n",
       "      <td>191265</td>\n",
       "      <td>chronic</td>\n",
       "      <td>B-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543399</th>\n",
       "      <td>4543400</td>\n",
       "      <td>29999</td>\n",
       "      <td>191265</td>\n",
       "      <td>hepatitis</td>\n",
       "      <td>I-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543432</th>\n",
       "      <td>4543433</td>\n",
       "      <td>29999</td>\n",
       "      <td>191267</td>\n",
       "      <td>serum</td>\n",
       "      <td>B-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543433</th>\n",
       "      <td>4543434</td>\n",
       "      <td>29999</td>\n",
       "      <td>191267</td>\n",
       "      <td>hepatitis</td>\n",
       "      <td>I-indications</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97627 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  Doc_ID  Sent_ID           Word            tag\n",
       "171          172       1        8     strategies  B-indications\n",
       "211          212       2       10  MICROCEPHALIA  B-indications\n",
       "212          213       2       10           VERA  I-indications\n",
       "233          234       3       12       reactive  B-indications\n",
       "234          235       3       12      hyperemia  I-indications\n",
       "...          ...     ...      ...            ...            ...\n",
       "4543377  4543378   29999   191264      hepatitis  I-indications\n",
       "4543398  4543399   29999   191265        chronic  B-indications\n",
       "4543399  4543400   29999   191265      hepatitis  I-indications\n",
       "4543432  4543433   29999   191267          serum  B-indications\n",
       "4543433  4543434   29999   191267      hepatitis  I-indications\n",
       "\n",
       "[97627 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['tag'] != 'O']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Train & Test Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 2 sentences in a word list format:\n",
      " [[('Obesity', 'O'), ('in', 'O'), ('Low-', 'O'), ('and', 'O'), ('Middle-Income', 'O'), ('Countries', 'O'), (':', 'O'), ('Burden', 'O'), (',', 'O'), ('Drivers', 'O'), (',', 'O'), ('and', 'O'), ('Emerging', 'O'), ('Challenges', 'O'), ('.', 'O')], [('We', 'O'), ('have', 'O'), ('reviewed', 'O'), ('the', 'O'), ('distinctive', 'O'), ('features', 'O'), ('of', 'O'), ('excess', 'O'), ('weight', 'O'), (',', 'O'), ('its', 'O'), ('causes', 'O'), (',', 'O'), ('and', 'O'), ('related', 'O'), ('prevention', 'O'), ('and', 'O'), ('management', 'O'), ('efforts', 'O'), (',', 'O'), ('as', 'O'), ('well', 'O'), ('as', 'O'), ('data', 'O'), ('gaps', 'O'), ('and', 'O'), ('recommendations', 'O'), ('for', 'O'), ('future', 'O'), ('research', 'O'), ('in', 'O'), ('low-', 'O'), ('and', 'O'), ('middle-income', 'O'), ('countries', 'O'), ('(', 'O'), ('LMICs', 'O'), (')', 'O'), ('.', 'O')]]\n",
      "First 2 sentences in a word list format:\n",
      " [['CCCVA', ',', 'MANOVA', ',', 'my', 'black', 'hen', '.'], ['Comments', 'on', 'repeated', 'measures', '.']]\n"
     ]
    }
   ],
   "source": [
    "def get_tagged_sentences(data):\n",
    "\n",
    "# Objective: To get list of sentences along with labelled tags.\n",
    "# Returns a list of lists of (word,tag) tuples.\n",
    "# Each inner list contains a words of a sentence along with tags.\n",
    "\n",
    "    agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(), s[\"tag\"].values.tolist())]\n",
    "    grouped = data.groupby(\"Sent_ID\").apply(agg_func)\n",
    "    sentences = [s for s in grouped]\n",
    "    return sentences\n",
    " \n",
    "def get_test_sentences(data):\n",
    "\n",
    "# Objective: To get list of sentences.\n",
    "# Returns a list of lists of words.\n",
    "# Each inner list contains a words of a sentence.\n",
    "\n",
    " \n",
    "    agg_func = lambda s: [w for w in s[\"Word\"].values.tolist()]\n",
    "    grouped = data.groupby(\"Sent_ID\").apply(agg_func)\n",
    "    sentences = [s for s in grouped]\n",
    "    return sentences\n",
    "# Getting training sentences in a list\n",
    "sentences = get_tagged_sentences(data)\n",
    "print(\"First 2 sentences in a word list format:\\n\",sentences[0:2])\n",
    "\n",
    "# Getting test sentences in a list\n",
    "test_sentences = get_test_sentences(test_data)\n",
    "print(\"First 2 sentences in a word list format:\\n\",test_sentences[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction for DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting words to indices for test sentences (Features)\n",
    "# Converting greek characters to ASCII characters in train set eg. 'naïve café' to 'naive cafe'\n",
    "X = [[word2idx[unicodedata.normalize('NFKD', str(w[0])).\n",
    "encode('ascii','ignore')] for w in s] for s in sentences]\n",
    " \n",
    "# Converting words to indices for test sentences (Features)\n",
    "# Converting greek characters to ASCII characters in test-set eg. 'naïve café' to 'naive cafe'\n",
    "X_test = [[word2idx[unicodedata.normalize('NFKD', str(w)).\n",
    "encode('ascii','ignore')] for w in s] for s in test_sentences]\n",
    " \n",
    "'''\n",
    "Padding train and test sentences to 180 words.\n",
    "Sentences of length greater than 180 words are truncated.\n",
    "Sentences of length less than 180 words are padded with a high value.\n",
    "'''\n",
    "X = pad_sequences(maxlen=MAXLEN, sequences=X, padding=\"post\", value=n_words - 1)\n",
    "X_test = pad_sequences(maxlen=MAXLEN, sequences=X_test, padding=\"post\", value=n_words - 1)\n",
    " \n",
    "# Converting tags to indices for test sentences (labels)\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "# Padding tag labels to 180 words.\n",
    "y = pad_sequences(maxlen=MAXLEN, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    " \n",
    "# Making labels in one hot encoded form for DL model\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Bidirectional LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 181717 samples, validate on 9565 samples\n",
      "Epoch 1/2\n",
      "181717/181717 [==============================] - 1056s 6ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 2/2\n",
      "181717/181717 [==============================] - 1108s 6ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0039 - val_accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "# 180 dimensional word indices as input\n",
    "input = Input(shape=(MAXLEN,))\n",
    " \n",
    "# Embedding layer of same length output (180 dim embedding will be generated)\n",
    "model = Embedding(input_dim=n_words, output_dim=MAXLEN, input_length=MAXLEN)(input)\n",
    " \n",
    "# Adding dropout layer\n",
    "model = Dropout(0.2)(model)\n",
    " \n",
    "# Bidirectional LSTM to learn from both forward as well as backward context\n",
    "model = Bidirectional(LSTM(units=LSTM_N, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    " \n",
    "# Adding a TimeDistributedDense, to applying a Dense layer on each 180 timesteps\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model) # softmax output layer\n",
    "model = Model(input, out)\n",
    " \n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X, np.array(y), batch_size=BS, epochs=2, validation_split=0.05, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 180, 180)          46296540  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 180, 180)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 180, 300)          397200    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 180, 3)            903       \n",
      "=================================================================\n",
      "Total params: 46,694,643\n",
      "Trainable params: 46,694,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Probabilities on Test Set:\n",
      " (125840, 180, 3)\n",
      "Predicted tag indices: \n",
      " (125840, 180)\n"
     ]
    }
   ],
   "source": [
    "# Predicting on trained model\n",
    "pred = model.predict(X_test)\n",
    "print(\"Predicted Probabilities on Test Set:\\n\",pred.shape)\n",
    "# taking tag class with maximum probability\n",
    "pred_index = np.argmax(pred, axis=-1)\n",
    "print(\"Predicted tag indices: \\n\",pred_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of words in Padded test set: 22651200\n",
      "Length of tags in Padded test set: 22651200\n",
      "\n",
      "Check few of words and predicted tags:\n",
      " ['CCCVA', ',', 'MANOVA', ',', 'my', 'black', 'hen', '.', 'ENDPAD', 'ENDPAD'] ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Flatten both the features and predicted tags for submission\n",
    "ids,tagids = X_test.flatten().tolist(), pred_index.flatten().tolist()\n",
    " \n",
    "# converting each word indices back to words\n",
    "words_test = [words[ind].decode('utf-8') for ind in ids]\n",
    "# converting each predicted tag indices back to tags\n",
    "tags_test = [tags[ind] for ind in tagids]\n",
    "print(\"Length of words in Padded test set:\",len(words_test))\n",
    "print(\"Length of tags in Padded test set:\",len(tags_test))\n",
    "print(\"\\nCheck few of words and predicted tags:\\n\",words_test[:10],tags_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose the two lists into a panda Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'words':words_test,'tags':tags_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCCVA</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MANOVA</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>black</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hen</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENDPAD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENDPAD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    words tags\n",
       "0   CCCVA    O\n",
       "1       ,    O\n",
       "2  MANOVA    O\n",
       "3       ,    O\n",
       "4      my    O\n",
       "5   black    O\n",
       "6     hen    O\n",
       "7       .    O\n",
       "8  ENDPAD    O\n",
       "9  ENDPAD    O"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a flavor of some of the words labeled by the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>Pasteurella</td>\n",
       "      <td>B-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>multocida</td>\n",
       "      <td>I-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>Breast</td>\n",
       "      <td>B-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>cancer</td>\n",
       "      <td>I-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>breast</td>\n",
       "      <td>B-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22646703</th>\n",
       "      <td>pigmentosa</td>\n",
       "      <td>I-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22647968</th>\n",
       "      <td>disorders</td>\n",
       "      <td>I-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22648506</th>\n",
       "      <td>excitable</td>\n",
       "      <td>B-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22648687</th>\n",
       "      <td>excitable</td>\n",
       "      <td>B-indications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22649230</th>\n",
       "      <td>excitable</td>\n",
       "      <td>B-indications</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49156 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                words           tags\n",
       "1991      Pasteurella  B-indications\n",
       "1992        multocida  I-indications\n",
       "4680           Breast  B-indications\n",
       "4681           cancer  I-indications\n",
       "4872           breast  B-indications\n",
       "...               ...            ...\n",
       "22646703   pigmentosa  I-indications\n",
       "22647968    disorders  I-indications\n",
       "22648506    excitable  B-indications\n",
       "22648687    excitable  B-indications\n",
       "22649230    excitable  B-indications\n",
       "\n",
       "[49156 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['tags'] != 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
